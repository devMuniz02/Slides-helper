# Slides-helper ğŸ¤ğŸ“Š

A local-first, multimodal AI agent that transforms PowerPoint slides into narrated experiences. Built with LangGraph & LM Studio to analyze visuals, generate executive summaries, and provide real-time presentation assistance.

## Features

- ğŸ” **Slide Processing**: Extract text, images, and metadata from PowerPoint (.pptx) files
- ğŸ‘ï¸ **Vision Analysis**: Analyze slide visuals using local Vision models (Qwen2.5-VL via LM Studio)
- ğŸ—£ï¸ **Text-to-Speech**: Generate natural narrations using edge-tts or other TTS engines
- ğŸ”„ **LangGraph Orchestration**: Modular workflow management for complex processing pipelines
- ğŸ’» **Local-First**: All processing happens on your machine - no cloud dependencies
- âš¡ **Efficient**: Optimized for 32GB RAM and 12GB VRAM systems
- ğŸ–¥ï¸ **PowerPoint Integration**: Real-time connection to active PowerPoint presentations
- ğŸ›ï¸ **Graphical Interface**: Modern GUI for live slide monitoring and analysis
- ğŸ“Š **Live Monitoring**: Automatically tracks current slide changes during presentations
- ğŸ¤ **TTS with Progressive Subtitles**: Generate summaries and speak them with synchronized, sentence-by-sentence subtitle overlay

## Prerequisites

- **Python 3.8+**
- **LM Studio** running locally with a vision-capable model (e.g., Qwen2.5-VL)
- **PowerPoint** (for GUI integration features)
- **Windows** (required for PowerPoint COM automation)

## Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd slides-helper
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up LM Studio:**
   - Download and install [LM Studio](https://lmstudio.ai/)
   - Download a vision model (e.g., Qwen2.5-VL)
   - Start LM Studio and load the model
   - Ensure LM Studio is running on `http://localhost:1234` (default)

## Configuration

Create a `.env` file in the project root (optional, defaults will work):

```env
# LM Studio Configuration
LM_STUDIO_BASE_URL=http://localhost:1234/v1
VISION_MODEL_NAME=Qwen2.5-VL

# TTS Configuration
TTS_ENGINE=edge-tts
TTS_VOICE=en-US-AriaNeural

# Processing Configuration
MAX_SLIDES_PER_BATCH=5
IMAGE_QUALITY=high
OUTPUT_DIR=./output
TEMP_DIR=./temp
```

## Usage

### Command Line Interface

Process a PowerPoint file:
```bash
python main.py path/to/your/presentation.pptx
```

With options:
```bash
python main.py path/to/presentation.pptx --output-dir ./my_output --stream
```

Available options:
- `--output-dir`: Specify output directory (default: ./output)
- `--stream`: Enable streaming progress updates
- `--gui`: Launch graphical interface instead

### Graphical User Interface

Launch the GUI for real-time PowerPoint integration:
```bash
python gui_launcher.py
```

Or from main script:
```bash
python main.py --gui
```

The GUI provides:
- Live slide monitoring during presentations
- Real-time analysis and narration
- Visual feedback and controls

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PowerPoint     â”‚    â”‚   PowerPoint GUI     â”‚
â”‚  (.pptx file)   â”‚    â”‚   (Live Integration) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 v                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Slide Processor Module                      â”‚
â”‚  â€¢ Extract text, images, speaker notes                  â”‚
â”‚  â€¢ Parse slide structure and metadata                   â”‚
â”‚  â€¢ Real-time slide extraction from active presentations â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Vision Analyzer Module                         â”‚
â”‚  â€¢ LM Studio Integration (Qwen2.5-VL)                   â”‚
â”‚  â€¢ Visual content analysis                              â”‚
â”‚  â€¢ Generate descriptions and summaries                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             TTS Engine Module                            â”‚
â”‚  â€¢ edge-tts for speech synthesis                        â”‚
â”‚  â€¢ Generate audio narrations                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Orchestrator Module                           â”‚
â”‚  â€¢ LangGraph workflow management                        â”‚
â”‚  â€¢ Coordinate all processing steps                      â”‚
â”‚  â€¢ Handle errors and state management                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
slides-helper/
â”œâ”€â”€ main.py                 # Command-line interface
â”œâ”€â”€ gui_launcher.py         # GUI launcher script
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ src/
    â”œâ”€â”€ gui/                # Graphical user interface
    â”œâ”€â”€ orchestrator/       # LangGraph orchestration
    â”œâ”€â”€ powerpoint_connector/ # PowerPoint integration
    â”œâ”€â”€ slide_processor/    # Slide content extraction
    â”œâ”€â”€ tts_engine/         # Text-to-speech synthesis
    â”œâ”€â”€ utils/              # Configuration and utilities
    â””â”€â”€ vision_analyzer/    # AI vision analysis
```

## Troubleshooting

### Common Issues

1. **LM Studio Connection Failed**
   - Ensure LM Studio is running and accessible at `http://localhost:1234`
   - Check that the vision model is loaded and active

2. **PowerPoint Integration Issues**
   - Ensure PowerPoint is installed and running
   - Run as administrator if COM automation fails

3. **TTS Engine Problems**
   - Verify internet connection for edge-tts
   - Check voice availability with `edge-tts --list-voices`

### Performance Optimization

- Use models optimized for your hardware (12GB VRAM recommended)
- Process fewer slides per batch for lower-end systems
- Enable streaming mode for progress feedback

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.</content>
<parameter name="filePath">c:\Users\emman\Desktop\PROYECTOS_VS_CODE\PRUEBAS_DE_PYTHON\Slides-helper\README.md
